{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Future Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains the code for modelling sales data per month. Stationarity and Seasonality are explored, and an ARIMA model is set up, as well as a Prophet model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"sales_train_v2.csv\", parse_dates=['date'])\n",
    "ts=data.groupby([\"date\"])[\"item_cnt_day\"].sum()\n",
    "ts=ts.reset_index()\n",
    "ts.head()\n",
    "data.dtypes\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this data sums total company sales per month. Sales per day can also be explored by changed the code to:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts=data.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n",
    "#ts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n",
    "#ts=ts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"sales_train_v2.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function tests the stationarity (ensuring mean, variance, autocorrelation) of the time series data. The data will be plotted, along with the rolling mean and rolling standard deviation of the data(the window can be adjusted accordingly in the function). The Dickey fuller test can be used as a further test of stationarity. The 'Test Statistic' should be negative, and less than the 5% critical value provided, the p-value can also be checked, and should be less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window = 12)\n",
    "    rolstd = pd.rolling_std(timeseries, window = 12)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the log transformation of the data, and see if this makes the data look more stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ts=log(ts)\n",
    "test_stationarity(log_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try removing moving average from the data, to test stationarity, again the window can be changed depending on the period of the time series. NA values will be created for the first 12 values, so these need dropped to investigate the stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = pd.rolling_mean(ts,12)\n",
    "plt.plot(ts)\n",
    "plt.plot(moving_avg, color='red')\n",
    "\n",
    "ts_moving_avg_diff = ts - moving_avg\n",
    "ts_moving_avg_diff.head(12)\n",
    "\n",
    "ts_moving_avg_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_moving_avg_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try shifting the data one place(can also be shifted more places), again 1 NA value will be created and will need to be omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff = ts - ts.shift()\n",
    "plt.plot(ts_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_diff.dropna(inplace=True)\n",
    "test_stationarity(ts_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, seasonality needs to be explored. Seasonality is the occurance of variation in time series data at a recurring and predictable time within a period, often a year. Since this data is monthly, the freq=12 for 12 months in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(ts, freq=12)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the trend, seasonality and residual components of the time series against the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(411)\n",
    "plt.plot(ts, label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autocorrelation and Partial Autocorrelation Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At lag k, this is the correlation between series values that are k intervals apart.\n",
    "\n",
    "Partial autocorrelation function (PACF). At lag k, this is the correlation between series values that are k intervals apart, accounting for the values of the intervals between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_acf = acf(ts_diff, nlags=20)\n",
    "lag_pacf = pacf(ts_diff, nlags=20, method='ols')\n",
    "\n",
    "#Plot ACF\n",
    "plt.subplot(121) \n",
    "plt.plot(lag_acf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "plt.title('Autocorrelation Function')\n",
    "\n",
    "#Plot PACF:\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf)\n",
    "plt.axhline(y=0,linestyle='--',color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for the ARIMA model. This is the area I am struggling with, as the predictions are not good. The parameters of the model can be changed (order=(p,d,q)) where p – number of time lags, d – degree of differencing and q – order of moving average model.\n",
    "\n",
    "The plots plot the data and the results of the ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(ts, order=(1, 1, 1))  \n",
    "results_ARIMA = model.fit(disp=-1)  \n",
    "plt.plot(ts_diff)\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red')\n",
    "plt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_diff)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adjusts the data if it was lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
    "predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n",
    "print( predictions_ARIMA_diff_cumsum.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This re-indexes the results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\n",
    "print (predictions_ARIMA_diff.head())\n",
    "predictions_ARIMA = pd.Series(ts.ix[0], index=ts.index)\n",
    "predictions_ARIMA = predictions_ARIMA.add(predictions_ARIMA_diff_cumsum,fill_value=0)\n",
    "predictions_ARIMA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the exponent if the TS was given a log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ARIMA = np.exp(predictions_ARIMA_log)\n",
    "plt.plot(ts)\n",
    "plt.plot(predictions_ARIMA)\n",
    "plt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet Model (Total Company Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Prophet model for total company sales per month\n",
    "\n",
    "The RMSE needs to be found for these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "#Creating Appropriate Dataframe #\n",
    "proph = data.groupby(['date_block_num'])[ 'item_cnt_day'].sum()\n",
    "proph.index=pd.date_range(start='2013-01-01', end='2015-10-01', freq='MS')\n",
    "proph = proph.to_frame().reset_index()\n",
    "proph.columns = ['ds', 'y']\n",
    "proph.head()\n",
    "#Modelling#\n",
    "model=Prophet(yearly_seasonality=True)\n",
    "model.fit(proph)\n",
    "#Making future predictions\n",
    "future_data = model.make_future_dataframe(periods=1, freq='MS')\n",
    "forecast_data = model.predict(future_data)\n",
    "forecast = model.predict(future_data)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "#Plotting Results\n",
    "model.plot(forecast_data)\n",
    "model.plot_components(forecast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet Model (Individual Store Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Prophet Model predicts the total sales of each store in the data set.\n",
    "\n",
    "The RMSE needs to be found for these predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_shop_sales=data.groupby([\"date_block_num\",\"shop_id\"])[\"item_cnt_day\"].sum()\n",
    "# get the shops to the columns\n",
    "monthly_shop_sales=monthly_shop_sales.unstack(level=1)\n",
    "monthly_shop_sales=monthly_shop_sales.fillna(0)\n",
    "monthly_shop_sales.index=dates\n",
    "monthly_shop_sales=monthly_shop_sales.reset_index()\n",
    "monthly_shop_sales.head()\n",
    "\n",
    "forecastsDict = {}\n",
    "for node in range(len(monthly_shop_sales)):\n",
    "    # take the date-column and the col to be forecasted\n",
    "    nodeToForecast = pd.concat([monthly_shop_sales.iloc[:,0], monthly_shop_sales.iloc[:, node+1]], axis = 1)\n",
    "    # rename for prophet compatability\n",
    "    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n",
    "    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n",
    "    growth = 'linear'\n",
    "    m = Prophet(growth, yearly_seasonality=True)\n",
    "    m.fit(nodeToForecast)\n",
    "    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n",
    "    forecastsDict[node] = m.predict(future)\n",
    "\n",
    "nCols = len(list(forecastsDict.keys()))+1\n",
    "for key in range(0, nCols-1):\n",
    "    f1 = np.array(forecastsDict[key].yhat)\n",
    "    f2 = f1[:, np.newaxis]\n",
    "    if key==0:\n",
    "        predictions=f2.copy()\n",
    "       # print(predictions.shape)\n",
    "    else:\n",
    "       predictions = np.concatenate((predictions, f2), axis = 1)\n",
    "       \n",
    "predictions_unknown=predictions[-1]\n",
    "predictions_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model (Individual Item-Store Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This XGBoost model could predict the next months sales of each item in each store. This code is running errors I can't work out, therefore I havent been able to tune the parameters to create the best predictions. I think it just needs something tweaking to get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "param = {'max_depth':10, \n",
    "         'subsample':1,\n",
    "         'min_child_weight':0.5,\n",
    "         'eta':0.3, \n",
    "         'num_round':1000, \n",
    "         'seed':1,\n",
    "         'silent':0,\n",
    "         'eval_metric':'rmse'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbtrain = xgb.DMatrix(train.iloc[:,  (train.columns != 33)].values, train.iloc[:, train.columns == 33].values)\n",
    "watchlist  = [(xgbtrain,'train-rmse')]\n",
    "\n",
    "bst = xgb.train(param, xgbtrain)\n",
    "preds = bst.predict(xgb.DMatrix(train.iloc[:,  (train.columns != 33)].values))\n",
    "from sklearn.metrics import mean_squared_error \n",
    "rmse = np.sqrt(mean_squared_error(preds,train.iloc[:, train.columns == 33].values))\n",
    "print(rmse)\n",
    "xgb.plot_importance(bst)\n",
    "apply_df = test\n",
    "apply_df['shop_id']= apply_df.shop_id.astype('str')\n",
    "apply_df['item_id']= apply_df.item_id.astype('str')\n",
    "\n",
    "apply_df = test.merge(train_cleaned_df, how = \"left\", on = [\"shop_id\", \"item_id\"]).fillna(0.0)\n",
    "d = dict(zip(apply_df.columns[4:],list(np.array(list(apply_df.columns[4:])) - 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
